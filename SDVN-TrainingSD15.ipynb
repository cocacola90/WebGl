{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pc-vaftMTxU"
      },
      "source": [
        "# [![](https://img.shields.io/badge/Thi·∫øt%20k·∫ø-stablediffusion.vn-0075ff)](https://stablediffusion.vn) [![](https://img.shields.io/badge/Phi√™n%20b·∫£n-v3-0075ff)](https://stablediffusion.vn) [![](https://img.shields.io/badge/Legacy-Version-ff0000)](https://bit.ly/sdvndreamboot) [![](https://img.shields.io/badge/Group-Support-0075ff)](https://www.facebook.com/groups/stablediffusion.vn) [![](https://img.shields.io/badge/B·ªô%20c√¥ng%20c·ª•-ƒê·∫ßy%20ƒë·ªß-0075ff)](https://stablediffusion.vn/bo-cong-cu/) [![](https://img.shields.io/discord/813085864355037235?color=blue&label=Discord&logo=Discord)](https://discord.gg/5SEtApPeyG) [![](https://img.shields.io/badge/Kohya%20Setting-Wiki-Blue)](https://github.com/bmaltais/kohya_ss/wiki/LoRA-training-parameters) [![](https://img.shields.io/badge/Kho√°%20h·ªçc-SD-red)](https://hungdiffusion.com/)\n",
        "\n",
        "---\n",
        "# üí° H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng :\n",
        "\n",
        "\n",
        " - B1 : Chu·∫©n b·ªã th∆∞ m·ª•c ·∫£nh m·∫´u ƒë·ªÉ train theo ƒë√∫ng k√≠ch th∆∞·ªõc, t·∫£i l√™n drive, c√≥ th·ªÉ ph√¢n chia th∆∞ m·ª•c con\n",
        " - B1 : Ch·∫°y ph·∫ßn 1\n",
        " - B2 : Ch·ªânh Path ƒë·ªÉ d·∫´n ƒë·∫øn th∆∞ m·ª•c data ƒë√£ t·∫£i v√† ch·∫°y ph·∫ßn 2\n",
        " - B3 : Ch·ªânh c√°c th√¥ng s·ªë train t·∫°i m·ª•c 3 v√† ch·∫°y ph·∫ßn 3\n",
        " - B4 : Ch·∫°y m·ª•c 4 v√† theo d√µi k·∫øt qu·∫£ train\n",
        " ---\n",
        "\n",
        " üîª : L∆∞u √Ω quan tr·ªçng thay ƒë·ªïi theo m·ªói l·∫ßn train\n",
        "\n",
        " üî∏ : Gi√° tr·ªã tham kh·∫£o, c√≥ th·ªÉ ƒë·ªÉ m·∫∑c ƒë·ªãnh\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPT0DeMD761Z"
      },
      "source": [
        "# üîå 1. C√†i ƒë·∫∑t n·ªÅn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OKPLNy721RWN"
      },
      "outputs": [],
      "source": [
        "# @title Install\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#root_dir\n",
        "root_dir = \"/content\"\n",
        "repo_dir = f\"{root_dir}/Kohya-Colab\"\n",
        "training_dir = f\"{root_dir}/Train_Config\"\n",
        "pretrained_model = f\"{root_dir}/Train_model\"\n",
        "config_dir = f\"{training_dir}/Config\"\n",
        "#repo_dir\n",
        "accelerate_config = f\"{repo_dir}/accelerate_config/config.yaml\"\n",
        "tools_dir = f\"{repo_dir}/tools\"\n",
        "finetune_dir = f\"{repo_dir}/finetune\"\n",
        "\n",
        "!git clone https://github.com/StableDiffusionVN/SDVN-kohya-colab-sd15 {repo_dir}\n",
        "\n",
        "%run {repo_dir}/TrainScript.ipynb\n",
        "\n",
        "install_sd15train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8uu_uAj8GUw"
      },
      "source": [
        "# üìÇ 2. K·∫øt n·ªëi data Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Ccsl1_k31mtP"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "#@markdown ##<br>üîª 2.1 ƒê∆∞·ªùng d·∫´n th∆∞ m·ª•c d·ªØ li·ªáu trong drive\n",
        "#@markdown <br>üí° `C√≥ th·ªÉ b·ªè tr·ªëng RegFolder`\n",
        "TrainFolder = \"/content/drive/MyDrive/Chasis\"  # @param {type:'string'}\n",
        "RegFolder = \"\"  # @param {type:'string'}\n",
        "#@markdown <br>üí° `Weight c·ªßa th∆∞ m·ª•c ·∫£nh reg`\n",
        "Prior_loss_weight = 1  # @param {type:\"number\"}\n",
        "DataClean = False #@param {type:\"boolean\"}\n",
        "SubFolder = True\n",
        "#@markdown ##<br>üî∏ 2.2 T·∫°o caption t·ª± ƒë·ªông\n",
        "AutoCaption = \"Waifu-1.4\" # @param [\"none\", \"BLIP-Caption\", \"Waifu-1.4\"]\n",
        "Caption_Length = \"Medium\" # @param ['Short','Medium','Long']\n",
        "\n",
        "# @markdown üü° `Th√™m caption tu·ª≥ ch·ªçn`\n",
        "Custom_Caption = \"\" # @param {type:'string',placeholder:\"Nh·∫≠p t·ª´ kho√° tu·ª≥ ch·ªçn ho·∫∑c chu·ªói mu·ªën xo√° khi ch·ªçn ch·∫ø ƒë·ªô Remove\"}\n",
        "Remove_Caption = False #@param {type:\"boolean\"}\n",
        "Append = False\n",
        "# @markdown üü° `T·ª± ƒë·ªông nh·∫≠n t√™n th∆∞ m·ª•c con l√†m caption`\n",
        "AddFolderName = False #@param {type:\"boolean\"}\n",
        "SubFolder = True\n",
        "\n",
        "Cap_prompt = {\n",
        "    'Short':['<CAPTION>',10,30,0.8],\n",
        "    'Medium':['<DETAILED_CAPTION>',10,100,0.5],\n",
        "    'Long':['<MORE_DETAILED_CAPTION>',10,150,0.3]\n",
        "}\n",
        "\n",
        "Cap_extension = \".txt\"\n",
        "extension = Cap_extension\n",
        "\n",
        "if DataClean == True :\n",
        "    %cd {root_dir}\n",
        "    clean_directory(TrainFolder)\n",
        "\n",
        "if AutoCaption == \"Waifu-1.4\" :\n",
        "    %cd {finetune_dir}\n",
        "    config = {\n",
        "        \"_train_data_dir\": TrainFolder,\n",
        "        \"batch_size\": 6,\n",
        "        \"repo_id\": \"SmilingWolf/wd-v1-4-convnext-tagger-v2\",\n",
        "        \"recursive\": True,\n",
        "        \"remove_underscore\": True,\n",
        "        \"general_threshold\": Cap_prompt[Caption_Length][3],\n",
        "        \"character_threshold\": 0.2,\n",
        "        \"caption_extension\": Cap_extension,\n",
        "        \"max_data_loader_n_workers\": 2,\n",
        "        \"debug\": True,\n",
        "        \"undesired_tags\": \"\"\n",
        "    }\n",
        "    final_args = f\"python {finetune_dir}/tag_images_by_wd14_tagger.py {join_arg(config)}\"\n",
        "    print(final_args)\n",
        "    !{final_args}\n",
        "\n",
        "if AutoCaption == \"BLIP-Caption\" :\n",
        "    %cd {finetune_dir}\n",
        "    config = {\n",
        "        \"_train_data_dir\" : TrainFolder,\n",
        "        \"batch_size\" : 6,\n",
        "        \"beam_search\" : True,\n",
        "        \"min_length\" : Cap_prompt[Caption_Length][1],\n",
        "        \"max_length\" : Cap_prompt[Caption_Length][2],\n",
        "        \"debug\" : True,\n",
        "        \"caption_extension\" : Cap_extension,\n",
        "        \"max_data_loader_n_workers\" : 2,\n",
        "        \"recursive\" : True\n",
        "    }\n",
        "    final_args = f\"python {finetune_dir}/make_captions.py {join_arg(config)}\"\n",
        "    print(final_args)\n",
        "    !{final_args}\n",
        "\n",
        "if AddFolderName:\n",
        "  add_forder_name(TrainFolder)\n",
        "if Custom_Caption != \"\":\n",
        "  process_dir(TrainFolder, Custom_Caption, Append, Remove_Caption)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9G1MMaij5sBz"
      },
      "source": [
        "# ‚öôÔ∏è 3. C√†i ƒë·∫∑t Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WIStEcFBWBLC"
      },
      "outputs": [],
      "source": [
        "#@markdown ##<br>üîª 3.1 C√†i ƒë·∫∑t chung\n",
        "#@markdown <br>\n",
        "\n",
        "Train_Option = \"Lora\" #@param [\"Checkpoint\", \"Lora\"]\n",
        "Project_name = \"Vehicle\" #@param {type:\"string\",placeholder:\"Nh·∫≠p t√™n output\"}\n",
        "Output_Path = \"/content/drive/MyDrive/stable_diffusion_weights/myChassis\" #@param {'type':'string'}\n",
        "#@markdown <br>üí° `D√°n link t·∫£i ho·∫∑c link ƒë∆∞·ªùng d·∫´n drive ƒë·ªÉ s·ª≠ d·ª•ng model b·∫•t k·ª≥ ƒë·ªÉ train`\n",
        "Model_Train = \"StableDiffusion_v15.ckpt\"  #@param [\"\", \"StableDiffusion_v15.ckpt\", \"Chilloutmix\", \"RealisticVision51\", \"PhotographyProv8\", \"Deliberate\", \"DreamShaperv8\", \"A-ZovyaRPGv3\", \"HenmixRealv4\", \"Fantasticv65\", \"XXMix_9realisticv3\", \"MajicmixRealv6\", \"ReVAnimatedv122\", \"RunDiffusionFXv1\", \"BeautifulRealAsiansv6\", \"LEOSAM-MoonFilm-v2\",\"Counterfeit\", \"OrientalMix\", \"FishMix\", \"ThreeDelicacyv2\", \"GODofSIMP\", \"TheoldfishSpread\", \"Theoldfish\", \"NightSkyYOZORA\", \"GhostMixv2\", \"ToonYou-beta6\", \"ComicsArthemyv3\", \"MeinaMix-v11\", \"ManmaruMix-v2\"] {allow-input: true}\n",
        "Resume_Path = \"\" # @param {type:'string',placeholder:\"Nh·∫≠p t√™n ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c State n·∫øu mu·ªën train ti·∫øp t·ª´ backup\"}\n",
        "Save_State = False #@param {type:\"boolean\"}\n",
        "#@markdown <br>üí° `Tr∆∞·ªùng h·ª£p train v·ªõi SubFolder, ƒë·∫∑t t√™n th∆∞ m·ª•c sub theo c√∫ ph√°p \" {repeat}_{name}\" ƒë·ªÉ ƒë·∫∑t repeat cho t·ª´ng th∆∞ m·ª•c`\n",
        "Repeats = 24  # @param {type:\"number\"}\n",
        "Resolution = 768  # @param {type:\"slider\", min:512, max:1024, step:128}\n",
        "Optimizer_type = \"AdamW8bit\"  # @param [\"AdamW\", \"AdamW8bit\", \"Lion\", \"SGDNesterov\", \"SGDNesterov8bit\", \"DAdaptation\", \"AdaFactor\"]\n",
        "#@markdown <br>üí° `C√†i ƒë·∫∑t sao l∆∞u sau s·ªë v√≤ng n`\n",
        "Save_Every_N_Epochs = 1  # @param {type:\"number\"}\n",
        "#@markdown ##<br>üîª 3.2-A | Checkpoint Setting\n",
        "#@markdown <br>üí° `S·ª≠ d·ª•ng card T4, Batch size t·ªëi ƒëa t·ªõi size 512 l√† 4, v·ªõi size 768 l√† 2`\n",
        "Batch_size = 2  # @param {type:\"number\"}\n",
        "Learning_Rate = 1e-6  # @param {'type':'number'}\n",
        "#@markdown <br>üí° `S·ªë b∆∞·ªõc train t·ªëi ƒëa`\n",
        "Max_train_steps = 1000  # @param {type:\"number\"}\n",
        "#@markdown ##<br>üîª 3.2-B | Lora Setting\n",
        "#@markdown <br>\n",
        "LoRA_Network_Weights = \"\" # @param {'type':'string',placeholder:\"Nh·∫≠p ƒë∆∞·ªùng d·∫´n lora, n·∫øu mu·ªën train ti·∫øp v√†o lora b·∫•t k·ª≥\"}\n",
        "#@markdown üí° `S·ª≠ d·ª•ng card T4, Batch size t·ªëi ƒëa t·ªõi size 512 l√† 6, v·ªõi size 768 l√† 3`\n",
        "Lora_Batch_size = 3  # @param {'type':'number'}\n",
        "Network_dim = 64  # @param {'type':'number'}\n",
        "Network_alpha = 32 # @param {'type':'number'}\n",
        "Unet_Lr = 1e-4  # @param {'type':'number'}\n",
        "Text_encoder_Lr = 1e-4  # @param {'type':'number'}\n",
        "#@markdown <br>üí° `S·ªë v√≤ng train t·ªëi ƒëa`\n",
        "Epochs = 4  # @param {type:\"number\"}\n",
        "#@markdown <br>üí° `C√†i ƒë·∫∑t Lerning rate scheduler`\n",
        "Lr_scheduler = \"constant\"  # @param [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\", \"adafactor\"] {allow-input: false}\n",
        "Lr_power = 2 # @param {'type':'number'}\n",
        "Comment = \"creator by SD15\" # @param {'type':'string'}\n",
        "\n",
        "\n",
        "output_name = Project_name if Project_name != \"\" else \"project_name\"\n",
        "resume = Resume_Path\n",
        "save_state = Save_State\n",
        "optimizer_type = Optimizer_type\n",
        "save_every_n_epochs = Save_Every_N_Epochs\n",
        "training_comment = Comment\n",
        "dataset_repeats = Repeats\n",
        "max_train_steps = Max_train_steps if Train_Option == \"Checkpoint\" else None\n",
        "train_batch_size = Lora_Batch_size if Train_Option == \"Lora\" else Batch_size\n",
        "network_weights = LoRA_Network_Weights\n",
        "network_dim = Network_dim\n",
        "network_alpha = Network_alpha\n",
        "learning_rate = Learning_Rate if Train_Option == \"Checkpoint\" else None\n",
        "text_encoder_lr = Text_encoder_Lr\n",
        "unet_lr = Unet_Lr\n",
        "max_train_epochs = Epochs if Train_Option == \"Lora\" else None\n",
        "lr_scheduler = Lr_scheduler\n",
        "lr_scheduler_power = Lr_power if Lr_scheduler == \"polynomial\" else None\n",
        "lr_warmup_steps = 100 if Lr_scheduler == \"constant_with_warmup\" else None\n",
        "lr_scheduler_num_cycles = 2 if Lr_scheduler == \"cosine_with_restarts\" else None\n",
        "optimizer_args = \"[ \\\"scale_parameter=False\\\", \\\"relative_step=False\\\", \\\"warmup_init=False\\\" ]\" if  Optimizer_type == \"AdaFactor\" else None\n",
        "output_dir = f'{Output_Path}/{\"Lora\" if Train_Option == \"Lora\" else \"Model\"}'\n",
        "activation_word = output_name\n",
        "\n",
        "vae_link = \"https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt\"\n",
        "vae_name = \"vae.ckpt\"\n",
        "aria_down(vae_link,pretrained_model,vae_name)\n",
        "vae = f\"{pretrained_model}/{vae_name}\"\n",
        "\n",
        "file_path = f'{repo_dir}/model_lib.json'\n",
        "with open(file_path, 'r') as json_file:\n",
        "    modellist = json.load(json_file)\n",
        "\n",
        "pretrained_model_name_or_path = download_lib(Model_Train,modellist,pretrained_model)\n",
        "\n",
        "sample_prompt = f\"{config_dir}/sample_prompt.txt\"\n",
        "config_file = f\"{config_dir}/config_file.toml\"\n",
        "dataset_config = f\"{config_dir}/dataset_config.toml\"\n",
        "\n",
        "default_config_lora = f\"{repo_dir}/config/default_config_lora.json\"\n",
        "default_config_checkpoint = f\"{repo_dir}/config/default_config_checkpoint.json\"\n",
        "\n",
        "final_config(default_config_lora if  Train_Option == \"Lora\" else default_config_checkpoint,config_file)\n",
        "\n",
        "subsets = get_subsets(TrainFolder,RegFolder)\n",
        "\n",
        "config = {\n",
        "    \"general\": {\n",
        "        \"enable_bucket\": True,\n",
        "        \"caption_extension\": Cap_extension,\n",
        "        \"shuffle_caption\": True,\n",
        "        \"keep_tokens\": 0,\n",
        "        \"bucket_reso_steps\": 64,\n",
        "        \"bucket_no_upscale\": False,\n",
        "    },\n",
        "    \"datasets\": [\n",
        "        {\n",
        "            \"resolution\": Resolution,\n",
        "            \"min_bucket_reso\": 320,\n",
        "            \"max_bucket_reso\": 1280,\n",
        "            \"caption_dropout_rate\": 0,\n",
        "            \"caption_tag_dropout_rate\": 0,\n",
        "            \"caption_dropout_every_n_epochs\": 0,\n",
        "            \"flip_aug\": False,\n",
        "            \"color_aug\": False,\n",
        "            \"face_crop_aug_range\": None,\n",
        "            \"subsets\": subsets,\n",
        "        }\n",
        "    ],\n",
        "}\n",
        "\n",
        "config_str = toml.dumps(config)\n",
        "write_file(dataset_config, config_str)\n",
        "\n",
        "dir = random.choice(subsets)[\"image_dir\"]\n",
        "txt_files = [f for f in os.listdir(dir) if f.endswith('.txt')]\n",
        "sample = read_file(f\"{dir}/{random.choice(txt_files)}\")\n",
        "default_prompt = \"best quality --n worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry --w 512 --h 768 --l 7 --s 28 \"\n",
        "sample_str = f\"{sample},{default_prompt}\"\n",
        "write_file(sample_prompt, sample_str)\n",
        "\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXQ27FCL5tfd"
      },
      "source": [
        "# ‚è≥ 4.Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EJu4b9hqWBLD"
      },
      "outputs": [],
      "source": [
        "#@markdown #‚ñ∂Ô∏è Theo d√µi qu√° tr√¨nh v√† ki·ªÉm so√°t ch·∫•t l∆∞·ª£ng\n",
        "#@markdown *Ki·ªÉm tra sample t·∫°i ```{Output_Path}/sample```*\n",
        "#@markdown <br>*C√≥ th·ªÉ d·ª´ng b·∫•t c·ª© khi n√†o sample th·∫•y ∆∞ng √Ω*\n",
        "\n",
        "%cd {repo_dir}\n",
        "\n",
        "if Train_Option == \"Checkpoint\" :\n",
        "  train_file = \"train_db.py\"\n",
        "else :\n",
        "  train_file = \"train_network.py\"\n",
        "\n",
        "accelerate_conf = {\n",
        "    \"config_file\" : accelerate_config,\n",
        "    \"num_cpu_threads_per_process\" : 1,\n",
        "}\n",
        "\n",
        "train_conf = {\n",
        "    \"sample_prompts\" : sample_prompt,\n",
        "    \"dataset_config\" : dataset_config,\n",
        "    \"config_file\" : config_file\n",
        "}\n",
        "\n",
        "accelerate_args = join_arg(accelerate_conf)\n",
        "train_args = join_arg(train_conf)\n",
        "final_args = f\"accelerate launch {accelerate_args} {train_file} {train_args}\"\n",
        "print(final_args)\n",
        "!{final_args}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "0pc-vaftMTxU",
        "IPT0DeMD761Z"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}